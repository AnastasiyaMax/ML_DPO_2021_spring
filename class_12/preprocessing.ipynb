{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuJXIpfvrksG",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Работа-с-признаками\" data-toc-modified-id=\"Работа-с-признаками-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Работа с признаками</a></span><ul class=\"toc-item\"><li><span><a href=\"#Масштабирование\" data-toc-modified-id=\"Масштабирование-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Масштабирование</a></span></li><li><span><a href=\"#Стандартизация\" data-toc-modified-id=\"Стандартизация-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Стандартизация</a></span></li><li><span><a href=\"#Нормализация\" data-toc-modified-id=\"Нормализация-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Нормализация</a></span></li><li><span><a href=\"#Методы-заполнения-пропусков\" data-toc-modified-id=\"Методы-заполнения-пропусков-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Методы заполнения пропусков</a></span></li><li><span><a href=\"#Методы-поиска-выбросов\" data-toc-modified-id=\"Методы-поиска-выбросов-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Методы поиска выбросов</a></span></li><li><span><a href=\"#Кодировки\" data-toc-modified-id=\"Кодировки-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Кодировки</a></span></li><li><span><a href=\"#Методы-работы-с-датами\" data-toc-modified-id=\"Методы-работы-с-датами-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Методы работы с датами</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "md1RJJXKrksO"
   },
   "source": [
    "## Работа с признаками\n",
    "\n",
    "Сегодня мы изучим такие важные темы для работы с признаками, как:\n",
    "\n",
    "1. масштабирование / нормализация / стандартизация\n",
    "2. методы заполнения пропусков\n",
    "3. методы поиска выбросов\n",
    "4. кодировки\n",
    "5. методы работы с датами\n",
    "\n",
    "В дополнение к пункту 1 данного урока настоятельно рекомендуем изучить [вот эту статью из документации](https://scikit-learn.org/stable/modules/preprocessing.html). Если остается время, то предлагаем обсудить дискретизацию, бинаризацию и полиномиальные признаки (рассмотрены в конце статьи).\n",
    "\n",
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20190312184006/Data-Preprocessing.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndfdndW3rksQ"
   },
   "source": [
    "### Масштабирование\n",
    "\n",
    "**Масштабирование** вектора (столбика наших данных) означает добавление или вычитание константы, а затем умножение или деление на константу, как если бы вы изменили единицы измерения данных, например, чтобы преобразовать температуру из Цельсия в Фаренгейт.\n",
    "\n",
    "\n",
    "Масштабирование можно выполнить с помощью функции [scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale)\n",
    "\n",
    "<img src=\"https://kharshit.github.io/img/scaling.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLucGlmmrksT"
   },
   "source": [
    "### Стандартизация\n",
    "\n",
    "**Стандартизация** вектора чаще всего означает вычитание меры местоположения и деление на меру масштаба. Например, если вектор содержит случайные значения с распределением Гаусса, вы можете вычесть среднее значение и разделить на стандартное отклонение, получив таким образом «стандартную нормальную» случайную величину со средним значением 0 и стандартным отклонением 1.\n",
    "\n",
    "Стандартизация признаков вокруг центра и 0 со стандартным отклонением 1 важна, когда мы сравниваем измерения, которые имеют разные единицы. Переменные, измеряемые в разных масштабах, не вносят равный вклад в анализ и могут в конечном итоге создать отклонение (bias).\n",
    "\n",
    "Например, переменная, которая находится в диапазоне от 0 до 1000, будет перевешивать переменную, которая находится в диапазоне от 0 до 1. Использование этих переменных без стандартизации даст переменной с большим весом диапазона 1000 в анализе. Преобразование данных в сопоставимые масштабы может предотвратить эту проблему. Типичные процедуры стандартизации данных уравнивают диапазон и / или изменчивость данных.\n",
    "\n",
    "Стандартизация предполагает, что ваши данные имеют распределение Гаусса (кривая колокола). Это не обязательно должно быть правдой, но этот метод более эффективен, если ваше распределение атрибутов гауссово. Стандартизация полезна, когда ваши данные имеют разные масштабы и алгоритм, который вы используете, делает предположения о том, что ваши данные имеют гауссовское распределение, например линейную регрессию, логистическую регрессию и линейный дискриминантный анализ.\n",
    "\n",
    "Популярные методы:\n",
    "\n",
    "1. [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler) масштабирует каждое наблюдение по его максимальному абсолютному значению. Он переводит каждый признак индивидуально, так что максимальное абсолютное значение каждой функции в обучающем наборе будет 1.0. Он не смещает / центрирует данные и, следовательно, не уничтожает разреженность.\n",
    "\n",
    "2. [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)\n",
    "Стандартизация признаков путем удаления среднего и масштабирования до единичной дисперсии. Центрирование и масштабирование происходят независимо для каждого признака путем вычисления соответствующей статистики по выборкам в обучающем наборе. Затем среднее и стандартное отклонение сохраняются для использования в последующих данных с помощью `transform`.\n",
    "\n",
    "\n",
    "Стандартизация набора данных - обычное требование для многих моделей машинного обучения. Обычно это делается путем вычитания среднего и масштабирования до единичной дисперсии. Однако выбросы часто могут отрицательно влиять на выборочное среднее / дисперсию. В таких случаях медиана и межквартильный размах часто дают лучшие результаты.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/381/1*KrYzFzhLBjiQ89OvDld8Tw.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uJJAlB3rksW"
   },
   "source": [
    "### Нормализация\n",
    "\n",
    "**Нормализация** вектора чаще всего означает деление на норму вектора. Это также часто относится к изменению масштаба по минимуму и диапазону вектора, чтобы все элементы лежали между 0 и 1, таким образом приводя все значения числовых столбцов в наборе данных к общему масштабу.\n",
    "\n",
    "Цель нормализации - изменить значения числовых столбцов в наборе данных на общий масштаб, не искажая различия в диапазонах значений. Для машинного обучения каждый набор данных не требует нормализации. Это требуется только тогда, когда характеристики имеют разные диапазоны.\n",
    "\n",
    "Например, рассмотрим набор данных, содержащий две характеристики: возраст и доход (x2). Где возраст от 0 до 100 лет, а доход от 0 до 100 000 и выше. Доход примерно в 1000 раз превышает возраст. Итак, эти две функции находятся в очень разных диапазонах. Когда мы проводим дальнейший анализ, такой как, например, многомерная линейная регрессия, приписанный доход будет влиять на результат больше из-за его большего значения. Но это не обязательно означает, что он более важен как предсказатель. Итак, мы нормализуем данные, чтобы привести все переменные в один и тот же диапазон.\n",
    "\n",
    "Нормализация - хороший метод, который можно использовать, когда вы не знаете распределение ваших данных или когда вы знаете, что распределение не является гауссовым (кривая колокола). Нормализация полезна, когда ваши данные имеют разные масштабы, а алгоритм, который вы используете, не делает предположений о распределении ваших данных, например о k-ближайших соседях и искусственных нейронных сетях.\n",
    "\n",
    "Популярные методы:\n",
    "1. [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) масштабирует и переводит каждый признак индивидуально так, чтобы он находился в заданном диапазоне обучающего набора, например от нуля до единицы. Формулы выглядят так:\n",
    "\n",
    "```X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_scaled = X_std * (max - min) + min```\n",
    "\n",
    "2. Более простой метод [normalize.](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize)\n",
    "\n",
    "3. [RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler) Масштабирует признаки, используя статистику, устойчивую к выбросам. Этот скейлер удаляет медианное значение и масштабирует данные в соответствии с квантильным диапазоном (по умолчанию IQR: межквартильный диапазон). IQR - это диапазон между 1-м квартилем (25-й квантиль) и 3-м квартилем (75-й квантиль). Центрирование и масштабирование происходят независимо для каждой функции путем вычисления соответствующей статистики по выборкам в обучающем наборе. Затем медиана и межквартильный размах сохраняются для использования в последующих данных с использованием метода преобразования.\n",
    "\n",
    "<img src=\"https://kharshit.github.io/img/normalization.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7ZSIuSMrksZ"
   },
   "source": [
    "### Методы заполнения пропусков\n",
    "\n",
    "Отсутствующие значения отражают беспорядок реальных данных. Причин может быть множество - от человеческих ошибок при вводе данных, неправильных показаний датчиков до программных ошибок в конвейере обработки данных.\n",
    "\n",
    "Отсутствующие данные, вероятно, являются наиболее распространенным источником ошибок в вашем коде и причиной большей части обработки исключений. Если вы попытаетесь удалить их, вы можете резко уменьшить объем имеющихся данных - вероятно, худшее, что может случиться в машинном обучении.\n",
    "\n",
    "Тем не менее часто в недостающих точках данных есть скрытые закономерности. Эти закономерности могут дать дополнительное представление о проблеме, которую вы пытаетесь решить.\n",
    "\n",
    "Основные методы работы с пропущенными значениями выглядят так:\n",
    "1. Выкинуть строки с пропусками (если их немного)\n",
    "2. Выкинуть столбцы с большим количеством пропусков (если пропущенных значений больше 60-70% от всех данных)\n",
    "3. Заполнить средним / медианой или средним к соседей (для временных рядов). Удобно делать с помощью [fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)\n",
    "4. Обучить модель на предсказание пропущенных значений\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2444/1*_RA3mCS30Pr0vUxbp25Yxw.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSgsj-Rgrksd"
   },
   "source": [
    "### Методы поиска выбросов\n",
    "\n",
    "**Выбросы** - это экстремальные значения, которые отклоняются от других наблюдений за данными, они могут указывать на изменчивость в измерениях, экспериментальные ошибки или новизну. Другими словами, выброс - это наблюдение, которое расходится с общей закономерностью выборки.\n",
    "\n",
    "**Типы выбросов**\n",
    "\n",
    "Выбросы могут быть двух видов: одномерные и многомерные. Одномерные выбросы можно найти, глядя на распределение значений в едином пространстве признаков. Многомерные выбросы можно найти в n-мерном пространстве (n-признаков). Рассмотрение распределений в n-мерном пространстве может быть очень трудным для человеческого восприятия, поэтому нам нужно обучить модель, которая будет делать это за нас.\n",
    "\n",
    "Выбросы также могут быть разных видов в зависимости от среды: точечные выбросы, контекстные выбросы или коллективные выбросы. Выбросы точек - это отдельные точки данных, которые находятся далеко от остальной части распределения. Контекстные выбросы могут быть шумом в данных, например знаками пунктуации при анализе текста или сигналом фонового шума при распознавании речи. Коллективные выбросы могут быть подмножествами новинок в данных, таких как сигнал, который может указывать на открытие новых явлений.\n",
    "\n",
    "**Наиболее частые причины выбросов в наборе данных:**\n",
    "\n",
    "* Ошибки ввода данных (человеческие ошибки)\n",
    "* Ошибки измерения (инструментальные ошибки)\n",
    "* Экспериментальные ошибки (извлечение данных или ошибки планирования / выполнения эксперимента)\n",
    "* Преднамеренный (фиктивные выбросы, сделанные для проверки методов обнаружения)\n",
    "* Ошибки обработки данных (манипуляции с данными или непреднамеренные изменения набора данных)\n",
    "* Ошибки выборки (извлечение или смешивание данных из неправильных или различных источников)\n",
    "* Естественный (не ошибка, новинки в данных)\n",
    "\n",
    "В процессе производства, сбора, обработки и анализа данных выбросы могут происходить из многих источников и скрываться во многих измерениях. Те, которые не являются результатом ошибки, называются новинками.\n",
    "\n",
    "Обнаружение выбросов имеет большое значение практически для любой количественной дисциплины (например, физики, экономики, финансов, машинного обучения, кибербезопасности). В машинном обучении и в любой количественной дисциплине качество данных так же важно, как и качество модели прогнозирования или классификации.\n",
    "\n",
    "Кроме того, при запуске квеста по обнаружению выбросов вы должны ответить на два важных вопроса о вашем наборе данных:\n",
    "\n",
    "* Какие и сколько функций я учитываю для обнаружения выбросов? (одномерный / многомерный)\n",
    "* Могу ли я предположить распределение значений для выбранных мной функций? (параметрический / непараметрический)\n",
    "\n",
    "Наиболее популярные методы обнаружения выбросов:\n",
    "1. Z-Score или анализ экстремальных значений (параметрический)\n",
    "2. Вероятностно-статистическое моделирование (параметрическое)\n",
    "3. Модели линейной регрессии (PCA, LMS)\n",
    "4. Модели на основе близости (непараметрические)\n",
    "5. Модели теории информации\n",
    "6. Методы обнаружения выбросов высокой размерности (разреженные данные большой размерности)\n",
    "\n",
    "На данном этапе обучения мы готовы рассмотреть несколько примеров.\n",
    "\n",
    "**Z-оценка** или **стандартная оценка наблюдения** - это показатель, который указывает, сколько стандартных отклонений точка данных находится от среднего значения выборки, при условии гауссовского распределения. Это делает z-оценку параметрическим методом. Очень часто точки данных не описываются гауссовым распределением, эта проблема может быть решена путем применения преобразований к данным, то есть масштабирования их.\n",
    "\n",
    "Некоторые библиотеки Python, такие как Scipy и Scikit Learn, имеют простые в использовании функции и классы для легкой реализации вместе с Pandas и Numpy.\n",
    "\n",
    "После выполнения соответствующих преобразований в выбранном пространстве объектов набора данных z-оценку любой точки данных можно вычислить с помощью следующего выражения:\n",
    "$$z=\\frac{x-\\mu}{\\sigma}$$\n",
    "\n",
    "При вычислении z-оценки для каждой выборки в наборе данных необходимо указать порог. Некоторыми хорошими пороговыми значениями \"правила большого пальца\" могут быть: 2,5, 3, 3,5 или более стандартных отклонений.\n",
    "\n",
    "<img src=\"https://mathbitsnotebook.com/Algebra2/Statistics/normalstandard.jpg\" width=600>\n",
    "\n",
    "«Помечая» или удаляя точки данных, которые лежат за пределами заданного порога, мы классифицируем данные на выбросы и не выбросы.\n",
    "\n",
    "**Использование межквартильного правила для поиска выбросов**\n",
    "\n",
    "Межквартильный размах можно использовать для обнаружения выбросов. Это делается с помощью следующих шагов:\n",
    "\n",
    "1. Рассчитайте межквартильный размах для данных.\n",
    "2. Умножьте межквартильный размах (IQR) на 1,5 (константа, используемая для распознавания выбросов).\n",
    "3. Прибавьте 1,5 x (IQR) к третьему квартилю. Любое число, превышающее это, является предполагаемым выбросом.\n",
    "4. Вычтите 1,5 x (IQR) из первого квартиля. Любое число меньше этого является предполагаемым выбросом.\n",
    "\n",
    "С помощью этого же правила рисуется ящик с усами. Вы можете его нарисовать в помощью [boxplot](https://seaborn.pydata.org/generated/seaborn.boxplot.html).\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/8000/1*0MPDTLn8KoLApoFvI0P2vQ.png\" width=700>\n",
    "\n",
    "Помните, что межквартильное правило - это всего лишь практическое правило, которое обычно выполняется, но не применяется к каждому случаю. В общем, вы всегда должны следить за своим анализом выбросов, изучая полученные выбросы, чтобы увидеть, имеют ли они смысл. Любой потенциальный выброс, полученный межквартильным методом, следует рассматривать в контексте всего набора данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuZKiFfHrkse"
   },
   "source": [
    "### Кодировки\n",
    "\n",
    "Это означает, что если ваши данные содержат категориальные данные, вы должны закодировать их в числа, прежде чем вы сможете подобрать и оценить модель.\n",
    "\n",
    "Двумя наиболее популярными методами являются целочисленное (integer) кодирование и one-hot кодирование, хотя более новый метод, называемый learned embedding (будет пройдено в курсе глубокого обучения), может обеспечить полезную золотую середину между этими двумя методами.\n",
    "\n",
    "**Как кодировать ординальные данные**\n",
    "\n",
    "Порядковое кодирование включает отображение каждой уникальной метки в целочисленное значение. Таким образом, это иногда называют просто целочисленным кодированием. Этот тип кодирования действительно подходит только в том случае, если существует известная ординальная взаимосвязь между категориями. \n",
    "\n",
    "Мы можем использовать [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder) из scikit-learn для кодирования каждой переменной в целые числа. Это удобный метод, который позволяет указывать порядок категорий в качестве аргументов, если такой порядок известен.\n",
    "\n",
    "Лучшая практика при кодировании переменных - подогнать кодировку в наборе обучающих данных, а затем применить ее к обучающим и тестовым наборам данных.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Bart_Baesens/publication/46429941/figure/tbl1/AS:669242856833040@1536571339783/The-thermometer-encoding-procedure-for-ordinal-variables.png\">\n",
    "\n",
    "\n",
    "**One-Hot кодирование**\n",
    "\n",
    "One-Hot кодирование подходит для категориальных данных, где нет связи между категориями.\n",
    "\n",
    "Он включает в себя представление каждой категориальной переменной двоичным вектором, который имеет один элемент для каждой уникальной метки, и маркировку метки класса 1, а всех остальных элементов 0.\n",
    "\n",
    "Например, если бы наша переменная была «цвет», а метки были «красными», «зелеными» и «синими», мы бы кодировали каждую из этих меток как трехэлементный двоичный вектор следующим образом:\n",
    "\n",
    "* Красный: [1, 0, 0]\n",
    "* Зеленый: [0, 1, 0]\n",
    "* Синий: [0, 0, 1]\n",
    "\n",
    "Затем каждая метка в наборе данных будет заменена вектором (один столбец становится тремя). Это делается для всех категориальных переменных, так что наши девять входных переменных или столбцов становятся 43 в случае набора данных по раку груди.\n",
    "\n",
    "Библиотека scikit-learn предоставляет [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) для автоматического горячего кодирования одной или нескольких переменных.\n",
    "\n",
    "**Кодировка по лейблам**\n",
    "\n",
    "Самый простой метод из рассмотренных. Просто кодирует слово в метку от 0 до число классов минус 1. Реализован в методе [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html).\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2736/0*T5jaa2othYfXZX9W.\">\n",
    "\n",
    "**Целевая кодировка (target encoding)**\n",
    "\n",
    "<img src=\"https://www.renom.jp/notebooks/tutorial/preprocessing/category_encoding/renom_cat_target.png\" width=700>\n",
    "\n",
    "**Целевое кодирование** - это процесс замены категориального значения средним значением целевой переменной. Его несложно реализовать самостоятельно. Если Вы решите так делать, то попробуйте добавить шума – при такой кодировке есть значительный риск переобучения. А есть готовый модуль из библиотеки H2O [Target Encoding](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-munging/target-encoding.html). В ней любые некатегориальные столбцы автоматически удаляются целевой моделью кодировщика.\n",
    "\n",
    "Еще один пример на всякий случай:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/680/1*6qNsNbcvT40YUbo_QpvGtA.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mgi5UF4Jrksh"
   },
   "source": [
    "### Методы работы с датами\n",
    "\n",
    "**Работа с датами на практике**\n",
    "\n",
    "Даты встречаются в большинстве данных, с которыми вам придётся работать на практике. Рассмотрим одну из таких задач.\n",
    "\n",
    "Вам приходит ежедневный отчёт по доходам проекта. Как правило, системы, предоставляющие финансовые данные, обновляют эту информацию в течение нескольких дней, то есть данные по доходам за вчерашний день будут немного корректироваться в течение 2-3 дней. В таких случаях хорошей практикой является обновление связанных отчётов не только за вчерашний день, но и за несколько предыдущих. Иначе отчёт будет расходиться с реальными финансовыми показателями.\n",
    "\n",
    "В таком случае необходимо задавать окно дат за последние несколько дней и запускать формирование отчёта за каждый из них. Например, если сегодня 2 марта, то пересчёт нужно запускать за последние 2 дня февраля и 1 марта. При этом нужно учитывать возможный високосный год. Для решения таких задач в Python есть множество готовых инструментов. Перед тем как познакомиться с ними, рассмотрим очень важный вопрос формата даты и времени.\n",
    "\n",
    "**Форматы дат и времени**\n",
    "\n",
    "В жизни мы привыкаем видеть даты в привычных для нас форматах. Например, запись 01.12.18 обычно означает 1 декабря 2018 года. Однако для жителей США эта дата окажется 12 января 2018 года, так как для них привычнее сначала указывать номер месяца, а потом день. Excel с настройками для России распознает эту дату как 1 декабря, а в американской локализации — как 12 января.\n",
    "\n",
    "Многие выгрузки из систем и баз данных имеют свой служебный формат. Например, формат времени из разных систем может отличаться:\n",
    "\n",
    "* 2018-11-09 15:45:21;\n",
    "* 11/09/2018 3:45:20 PM;\n",
    "* 2018-11-09T15:45:21.2984.\n",
    "\n",
    "Для всех этих случаев необходимо задавать формат распознавания дат, уметь сравнивать их между собой. Также часто необходимо корректно прибавлять к датам различные временные интервалы. Например, час или день.\n",
    "\n",
    "**Формат YYYY-MM-DD**\n",
    "\n",
    "Даты, с которыми мы работали в прошлых шагах, являются просто строками. Python пока не знает, на каком месте указан год, на каком — день или час. Для распознавания дат в Python введены обозначения, которые помогут системе правильно распознать практически любой формат даты и времени. Для этого необходимо указать в коде, что означает каждая цифра и буква. Рассмотрим простой пример, когда дата задана в следующем формате:\n",
    "\n",
    "`date_string = '2019-03-01'`\n",
    "\n",
    "Такой формат записи даты практичен и пользуется большой популярностью, так как в этой записи сортировка по алфавиту будет совпадать с календарем. Например, для привычного формата «01.03.2019» это неверно: в алфавитном порядке даты будут идти в другой последовательности, отличающейся от правильного порядка в календаре.\n",
    "\n",
    "**Распознавание дат в Python**\n",
    "\n",
    "Вернемся к переменной `date_string`. Что нужно, чтобы Python начал воспринимать эту строку как дату? Для начала необходимо явно указать, где в этой строке год, месяц и день:\n",
    "\n",
    "* 2019 — год;\n",
    "* 03 — месяц;\n",
    "* 01 — день.\n",
    "\n",
    "А также не забыть, что в такой записи между ними стоят дефисы «-». Для расшифровки даты и времени составлены таблицы:\n",
    "\n",
    "* [официальная документация](https://docs.python.org/3/library/datetime.html);\n",
    "* [вариант с русским переводом](https://all-python.ru/osnovy/modul-datetime.html).\n",
    "\n",
    "Вместо чисел в переменной `date_string` надо подставить подходящие форматы. Начнем с года:\n",
    "\n",
    "* %y — номер года без указания столетия (например, 19 для года 2019);\n",
    "* %Y — полный вариант записи (2019), который нам подходит.\n",
    "\n",
    "Подставляем вместо года его формат: '%Y-03-01'\n",
    "\n",
    "Теперь месяц:\n",
    "\n",
    "* %b — сокращенное название месяца вроде Jan, Feb;\n",
    "* %B — полное название месяца;\n",
    "* %m — номер месяца в числовом представлении (наш вариант).\n",
    "\n",
    "Добавляем расшифровку месяца: '%Y-%m-01'. Формат даты зависит от регистра: %m — номер месяца, а %M будет количеством минут.\n",
    "\n",
    "**Сложные форматы даты и времени**\n",
    "\n",
    "В Python можно распознать любой тип даты.\n",
    "\n",
    "Давайте укажем формат даты 2019-04-01T06:30:00 (6:30 утра 1 апреля 2019 года). Год, месяц и день мы уже расшифровали — их формат %Y-%m-%d.\n",
    "\n",
    "Далее идёт буква T, как и любой символ в дате его надо указать в формате: %Y-%m-%dT06:30:00.\n",
    "\n",
    "Далее идет номер часа:\n",
    "* %H — количество часов в 24-часовом формате;\n",
    "* %I — количество часов в 12-часовом формате.\n",
    "\n",
    "Нам подходят оба варианта. Для того, чтобы узнать точный вариант, необходимо выяснить пример даты после полудня. Используем вариант %H.\n",
    "\n",
    "**Формат unixtime**\n",
    "\n",
    "Популярным форматом записи даты и времени является unixtime (также POSIX-время). Это количество секунд, прошедших с полуночи 1 января 1970 года по часовой зоне UTC. Преимущество данного формата в его простоте: обычно это целое число. Также им удобно считать разницу между двумя датами: это будет разница двух чисел в секундах.\n",
    "\n",
    "Переводить дату в unixtime и обратно можно с помощью кода на Python или специальных онлайн-сервисов, например, onlineconversion.\n",
    "\n",
    "Пример перевода даты 18 марта 2014 в формат unixtime:\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/8BKVR.png\">\n",
    "\n",
    "На этом сайте используется американский формат ввода дат: сначала указывается месяц, потом день.\n",
    "\n",
    "**Библиотека datetime**\n",
    "\n",
    "Теперь, когда мы научились работать с форматами даты и времени в Python, можно познакомиться с библиотеками, которые позволяют получать массу полезной информации из этих данных. Начнем с небольшого замечания об импорте библиотеки datetime, который можно сделать двумя способами. Можно импортировать ее в код так:\n",
    "\n",
    "`import datetime`\n",
    "\n",
    "На текущем занятии мы будем использовать из этой библиотеки следующие модули:\n",
    "\n",
    "* datetime для распознавания формата дат,\n",
    "* timedelta для прибавления к текущей дате определенного временного интервала.\n",
    "Импортируем эти модули следующим образом:\n",
    "\n",
    "`from datetime import datetime, timedelta`\n",
    "\n",
    "Это избавит нас от необходимости писать 'datetime.' перед каждым вызовом модулей.\n",
    "\n",
    "До этого шага мы работали с датами как с обычными строками. Пора начать использовать полученные знания для практических задач, а именно переводить дату в виде строки в  переменную типа datetime. Это позволит нам использовать многочисленные возможности работы с датами: выделять из даты любой период (день, секунду), прибавлять и вычитать временные интервалы (например, вычитать из 1 марта 1 день с учетом високосных годов) и многое другое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OaKbIp3Hrksl"
   },
   "outputs": [],
   "source": [
    "date_string = '05.05.2019 21:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jkRxydTfrktF",
    "outputId": "d2106569-4057-4860-e340-aaacae66c2ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 5, 5, 21, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dt = datetime.strptime(date_string, '%d.%m.%Y %H:%M')\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oveViAjPrktk",
    "outputId": "113d6e4b-4a45-4ddd-88dd-168069776b0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2019, 5, 5, 21, 0, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uglq-bMfrktu"
   },
   "source": [
    "**Перевод даты в строку**\n",
    "\n",
    "Перед тем, как рассматривать другие практические применения типа переменных datetime, рассмотрим обратный процесс перевода даты в строку. Эта операция будет часто встречаться, так как результаты работы с датами обычно записываются в файлы как строки в удобном формате. Для этого действия предназначен метод strftime, который похож на strptime из прошлого шага.\n",
    "\n",
    "Зададим значение dt из прошлого шага ещё раз, не обязательно для этого использовать перевод из строки, можно задать дату и время напрямую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aX18qI5rktw"
   },
   "outputs": [],
   "source": [
    "dt = datetime(2019, 5, 5, 21, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71hICC3Crkt5"
   },
   "source": [
    "Как видно из синтаксиса, порядок следования периодов логичен: год, номер месяца, день, часы, минуты, секунды (не обязательно указывать все аргументы, но важно сохранять их порядок). Теперь для перевода даты dt в строку достаточно указать желаемый формат. Используем стандартный формат YYYY-MM-DD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yQ2eskn_rkt6",
    "outputId": "e63f2abe-466a-4c1d-8640-80e9ecd9ef32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19-05-05'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.strftime('%y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XKyjuDXrkuh"
   },
   "source": [
    "**Синтаксис и принцип работы timedelta**\n",
    "\n",
    "Необходимость прибавлять временной интервал к дате часто встречается в самых разнообразных задачах. Например, при заборе данных из внешних источников с помощью API для каждого дня отдельно (для увеличения точности выгрузки).\n",
    "\n",
    "Допустим, у нас есть дата начала выгрузки start_date. Необходимо прибавить к этой дате день: воспользуемся модулем timedelta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7q95W7e0rkuj"
   },
   "outputs": [],
   "source": [
    "start_date = '2019-02-28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tEDvZFcArkuz",
    "outputId": "dd3ef612-d8a2-43b7-a738-a52ad4e92b88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 2, 28, 0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Переводим строковую переменную start_date в формат datetime\n",
    "start_date_datetime = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "start_date_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iDslnR5Prku9",
    "outputId": "22fcbc4f-212d-4650-b903-fbe5d58f38bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 4, 23, 0, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import * \n",
    "\n",
    "start_date_datetime + timedelta(days = 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_g2wNPQArkvJ",
    "outputId": "6d170655-b94a-4099-9452-6133db098f50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 2, 21, 0, 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date_datetime + timedelta(days = -7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "14W5-W_4rkvZ",
    "outputId": "30a7b847-8dc3-4cb1-a8d8-401545467b9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 2, 28, 1, 0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date_datetime += timedelta(hours = 1)\n",
    "start_date_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBYUQnWMrkxI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "29_ml_preprocessing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
