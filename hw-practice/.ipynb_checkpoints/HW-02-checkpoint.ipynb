{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация градиентного спуска\n",
    "\n",
    "Реализуйте линейную регрессию с функцией потерь MSE, обучаемую с помощью:\n",
    "\n",
    "**Задание 1 (3 балла)** Градиентного спуска;\n",
    "\n",
    "**Задание 2 (4 балла)** Стохастического градиентного спуска.\n",
    "\n",
    "\n",
    "Во всех пунктах необходимо соблюдать следующие условия:\n",
    "\n",
    "* Все вычисления должны быть векторизованы;\n",
    "* Циклы средствами python допускается использовать только для итераций градиентного спуска;\n",
    "* В качестве критерия останова необходимо использовать (одновременно):\n",
    "\n",
    "    * проверку на евклидовую норму разности весов на двух соседних итерациях (например, меньше некоторого малого числа порядка $10^{-6}$, задаваемого параметром `tolerance`);\n",
    "    * достижение максимального числа итераций (например, 10000, задаваемого параметром `max_iter`).\n",
    "* Чтобы проследить, что оптимизационный процесс действительно сходится, будем использовать атрибут класса `loss_history` — в нём после вызова метода `fit` должны содержаться значения функции потерь для всех итераций, начиная с первой (до совершения первого шага по антиградиенту);\n",
    "* Инициализировать веса можно случайным образом или нулевым вектором. \n",
    "\n",
    "\n",
    "Ниже приведён шаблон класса, который должен содержать код реализации каждого из методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class LinearReg(BaseEstimator):\n",
    "    def __init__(self, gd_type='stochastic', \n",
    "                 tolerance=1e-4, max_iter=1000, w0=None, alpha=1e-3, eta=1e-2):\n",
    "        \"\"\"\n",
    "        gd_type: 'full' or 'stochastic' or 'momentum'\n",
    "        tolerance: for stopping gradient descent\n",
    "        max_iter: maximum number of steps in gradient descent\n",
    "        w0: np.array of shape (d) - init weights\n",
    "        eta: learning rate\n",
    "        alpha: momentum coefficient\n",
    "        \"\"\"\n",
    "        self.gd_type = gd_type\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iter = max_iter\n",
    "        self.w0 = w0\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "        self.eta = eta\n",
    "        self.loss_history = None \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        self.loss_history = []\n",
    "        #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.w is None:\n",
    "            raise Exception('Not trained yet')\n",
    "        #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "    \n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d) (ell can be equal to 1 if stochastic)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: np.array of shape (d)\n",
    "        \"\"\"\n",
    "        #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "\n",
    "    def calc_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: float \n",
    "        \"\"\" \n",
    "        #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3 (0 баллов)**. \n",
    "* Загрузите данные из домашнего задания 2 ([train.csv](https://www.kaggle.com/c/nyc-taxi-trip-duration/data));\n",
    "* Разбейте выборку на обучающую и тестовую в отношении 7:3 с random_seed=0;\n",
    "* Преобразуйте целевую переменную `trip_duration` как $\\hat{y} = \\log{(y + 1)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (3 балла)**. Обучите и провалидируйте модели на данных из предыдущего пункта, сравните качество между методами по метрикам MSE и $R^2$. Исследуйте влияние параметров `max_iter` и `eta` на процесс оптимизации. Согласуется ли оно с вашими ожиданиями?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
